Knowledge Graph Extraction
======

Two steps:
1. Name Entity Recogntion
2. Relation Extraction

Current Log Summary
------
Nov 14 - Dec 3, 2019
```
----- TO DO:
  1. Retrain, add misclassified to training
  2. Unknown words
  3. Relation extraction tools
  4. Sample annotations

----- Wrote:
  Modified: process.py, eval.py, eval_class.py, pred.py
  Added: relation.py

----- Results:
  1. 	Retrained model:
    > Nov_20_examples.txt
    =============== Class:  Person ===============
    	tp, fp, fn counts:  [87, 13, 6]
    	Precision:  0.87
    	Recall:  0.9354838709677419
    	F1 score:  0.9015544041450777

    =============== Class:  Rank ===============
    	tp, fp, fn counts:  [80, 14, 11]
    	Precision:  0.851063829787234
    	Recall:  0.8791208791208791
    	F1 score:  0.8648648648648649

    =============== Class:  Organization ===============
    	tp, fp, fn counts:  [103, 33, 31]
    	Precision:  0.7573529411764706
    	Recall:  0.7686567164179104
    	F1 score:  0.762962962962963

    =============== Class:  Title_Role ===============
    	tp, fp, fn counts:  [85, 20, 23]
    	Precision:  0.8095238095238095
    	Recall:  0.7870370370370371
    	F1 score:  0.7981220657276995

    =============== All classes ===============
    	Precision:  0.8160919540229885
    	Recall:  0.8333333333333334
    	F1 score:  0.8246225319396051

  2. Unknown words:
      It turns out that the model handles unknown words automatically, which is implicitly done by tf.contrib.lookup.index_table_from_file (The following line is just a part of its documentation):Â 
      tf.contrib.lookup.index_table_from_file --- Any lookup of an out-of-vocabulary token will return a bucket ID based on its hash if num_oov_buckets is greater than zero. Otherwise it is assigned the default_value

  3. Relation extraction tools:
    > test_docs
    I have implemented a very simple relation extraction algorithm, which is simply assigning name entities to the nearest person. But this already produces some reasonable results.
    Results are included in 'test_docs', those files are in BRAT annotation format. So, the relations can be viewed in BRAT, just like the original annotations.
```

Files
------
> process.py:

1. preprocess dataset for convert_format.py by recording info in dicts, which are saved in two pickle files: dataset_labels.pickle, dataset_sentences.pickle
2. convert SFM starter dataset to a format that can be used by the model

>pred.py

generates predictions use the trained model. Before this, run python3 train.py

>eval.py

evaluate the predictions made by model, which are generated by running pred.py

>eval_class.py

For each individual class, evaluate the predictions made by model, which are generated by running pred.py

>relation.py

Extract relations between recognized name entities

Usage
------
1. Preprocess data
```shell
$ python3 process.py
$ cd SFM_STARTER
$ python3 build_vocab.py
$ python3 build_glove.py
$ cd ..
```

2. Train model
```shell
$ python3 train.py
```

3. Evaluate model
```shell
$ python3 pred.py
$ python3 eval.py
```

4. Relation extraction
```shell
$ python3 relation.py [input_file.txt]
$ cat [input_file.ann]
```

Name Entity Recognition
======
Dataset
------
For training, I used 400 sentences from SFM starter dataset and the first 5000 sentences from CONLL2003 training data.

Labels are mapped using this dict, define in [process.py](process.py):
```Python
label_mapping = {'Person':       'PER',
                 'Rank':         'RNK',
                 'Organization': 'ORG',
                 'Title':        'TOR',
                 'Role':         'TOR',
                 'Location':     'LOC'}
```


Training
------
Saving dict for global step 3472: acc = 0.92142266, f1 = 0.77824265, global_step = 3472, loss = 7.126516, precision = 0.7237354, recall = 0.84162897
Saving 'checkpoint_path' summary for global step 3472: results/model/model.ckpt-3472

Results
------
Output of [eval.py](eval.py) is included in [Nov_20_examples.txt](Nov_20_examples.txt)
```
=============== Class:  Person ===============
  tp, fp, fn counts:  [87, 13, 6]
  Precision:  0.87
  Recall:  0.9354838709677419
  F1 score:  0.9015544041450777

=============== Class:  Rank ===============
  tp, fp, fn counts:  [80, 14, 11]
  Precision:  0.851063829787234
  Recall:  0.8791208791208791
  F1 score:  0.8648648648648649

=============== Class:  Organization ===============
  tp, fp, fn counts:  [103, 33, 31]
  Precision:  0.7573529411764706
  Recall:  0.7686567164179104
  F1 score:  0.762962962962963

=============== Class:  Title_Role ===============
  tp, fp, fn counts:  [85, 20, 23]
  Precision:  0.8095238095238095
  Recall:  0.7870370370370371
  F1 score:  0.7981220657276995

=============== All classes ===============
  Precision:  0.8160919540229885
  Recall:  0.8333333333333334
  F1 score:  0.8246225319396051
```

Relation Extraction
======
Version 1
------
[Dec 3, 2019] simply assign name entities to the nearest person.
